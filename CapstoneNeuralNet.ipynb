{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p-nookala/advanced-git-lab/blob/main/CapstoneNeuralNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VecCAfTQ89wj"
      },
      "source": [
        "Import files from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZqRvZJi7yGC",
        "outputId": "fa64dff8-ebfa-482b-bb55-2f37211adf5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, Activation\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.metrics import CategoricalAccuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0gU5aIA9hbfH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQfzJXcM99XE"
      },
      "source": [
        "Change directory to labeled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgAYKn3R9-WT"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/content/drive/Shareddrives/Capstone/labeled_data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1zvtvoY_dWy"
      },
      "source": [
        "Import dataset and find dataset mean and stdev\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xa1OJFT_d_d",
        "outputId": "ef99f743-8d21-4992-ef9e-7e8c7255a1f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'TNT': 0, 'RDX': 1, 'TATP': 2, 'NOX': 3}\n",
            "910\n",
            "global mean:  [67.06183286 68.12081083 68.71126293]\n",
            "global stdev:  [98.20364101 98.00416065 99.89296153]\n"
          ]
        }
      ],
      "source": [
        "IMG_SIZE=256\n",
        "means = []\n",
        "stdevs = []\n",
        "images = []\n",
        "dirs = next(os.walk('.'))[1]\n",
        "\n",
        "# Generate numeric labels for each unique directory\n",
        "labels = {dir.split(\"_\")[0] for dir in dirs}\n",
        "label_dict = dict(zip(labels, [i for i in range(len(labels))]))\n",
        "print(label_dict)\n",
        "\n",
        "def generate_labeled_images(img_ary, isTrain=True):\n",
        "  labels = []\n",
        "  imgs = []\n",
        "  for file_path in img_ary:\n",
        "    image = cv2.imread(str(file_path))\n",
        "    if image is None or image.size == 0:\n",
        "      continue\n",
        "    # Might be worth putting this into a new directory on the drive to reduce training time...\n",
        "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image_float = np.float32(image)\n",
        "    # create image, label pairing\n",
        "    image_filename = os.path.basename(str(file_path))\n",
        "    label = \"NOX\" if image_filename[0]==\"n\" else str(file_path.parent).split(\"_\")[0]\n",
        "    label = label_dict[label]\n",
        "    imgs.append(image_float)\n",
        "    labels.append(label)\n",
        "    if isTrain:\n",
        "      means.append(np.mean(image, axis=(0, 1)))\n",
        "      stdevs.append(np.std(image, axis=(0, 1)))\n",
        "\n",
        "  return imgs, labels\n",
        "\n",
        "for dir in dirs:\n",
        "  for file_path in Path(dir+\"/original\").iterdir():\n",
        "    images.append(file_path)\n",
        "\n",
        "# if we want to make this reproducible\n",
        "# random.seed(482)\n",
        "random.shuffle(images)\n",
        "train_imgs = images[:int(.9 * len(images))]\n",
        "test_imgs = images[int(.9 * len(images)):]\n",
        "\n",
        "x_train, y_train = generate_labeled_images(train_imgs)\n",
        "x_test, y_test = generate_labeled_images(test_imgs, False)\n",
        "\n",
        "\n",
        "# cv2.rotate(src, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "# image = cv2.rotate(src, cv2.ROTATE_180)\n",
        "# image = cv2.rotate(src, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "print(len(x_train))\n",
        "# Compute the global mean and std dev\n",
        "global_mean = np.mean(means, axis=0)\n",
        "global_std = np.mean(stdevs, axis=0)\n",
        "\n",
        "print(\"global mean: \", global_mean)\n",
        "print(\"global stdev: \", global_std)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aeyt4FfM_fD3"
      },
      "source": [
        "Now we can read in the data and normalize the values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz-q509zS4vc"
      },
      "outputs": [],
      "source": [
        "def normalize_image(img, mean, std):\n",
        "    return (img - mean) / (std + 1e-7)\n",
        "\n",
        "for i in range(len(x_train)):\n",
        "  x_train[i] = normalize_image(x_train[i], global_mean, global_std)\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "    x_test[i] = normalize_image(x_test[i], global_mean, global_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CWKE4d6qcCP"
      },
      "source": [
        "We can trian the model now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soVq7rbIqkAo",
        "outputId": "1c975c34-142b-417e-dd95-49296c6fc98c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 3 3 3 3 1 3 3 0 1 1 2 3 3 3 3 3 3 3 1 1 3 3 1 3 3 3 3 2 3 3 3 3 1 2 3 1\n",
            " 3 3 3 3 3 2 0 1 1 0 0 3 1 0 0 3 1 3 3 2 3 1 3 3 1 3 3 3 1 3 0 3 3 3 2 3 3\n",
            " 3 3 3 1 0 3 0 2 2 3 0 1 3 3 3 3 3 3 3 3 2 3 1 3 3 3 0 2 3 3 3 3 0 1 1 2 3\n",
            " 3 3 0 2 3 1 0 3 2 3 1 3 3 2 0 0 0 3 2 1 0 3 1 1 0 1 3 1 3 3 3 3 3 3 0 1 0\n",
            " 3 3 3 2 3 1 2 3 3 3 0 0 3 3 3 2 1 1 3 3 3 0 1 1 1 3 1 3 3 2 3 3 3 1 1 0 3\n",
            " 3 3 3 3 3 3 0 3 3 3 0 3 2 3 3 1 2 3 0 3 3 1 1 2 3 1 1 0 2 3 3 3 3 3 3 3 0\n",
            " 0 0 3 2 3 3 3 1 3 0 3 3 3 1 3 3 3 0 3 3 2 0 1 3 3 0 3 3 3 0 3 1 3 3 1 1 3\n",
            " 3 3 1 1 1 2 3 3 2 3 3 3 1 3 3 3 3 3 3 3 3 3 3 0 3 2 3 0 3 3 3 3 3 1 0 3 3\n",
            " 3 1 1 1 1 2 0 3 3 3 3 2 3 3 0 1 1 3 3 3 2 3 1 1 3 3 3 3 3 1 3 3 1 3 0 3 3\n",
            " 1 3 3 3 1 3 3 3 2 3 1 1 3 1 3 3 0 3 3 3 0 0 3 3 0 3 1 3 3 3 3 3 3 3 0 3 3\n",
            " 3 3 0 3 3 3 1 3 1 2 1 2 1 3 1 3 3 1 1 3 1 2 3 0 3 2 2 1 3 0 3 3 3 0 3 3 3\n",
            " 3 3 3 3 3 1 1 3 3 3 3 3 1 3 3 3 3 3 1 3 1 3 3 0 0 0 3 3 3 3 3 1 3 1 3 3 3\n",
            " 1 3 2 3 1 3 1 0 3 3 3 3 0 3 3 1 3 3 0 1 1 3 3 0 3 0 1 3 1 3 3 2 3 3 1 3 3\n",
            " 1 3 3 2 1 2 3 3 3 1 3 2 3 1 3 1 1 0 3 2 3 3 1 2 3 3 0 3 3 3 1 2 3 3 0 1 0\n",
            " 3 2 1 1 3 2 1 3 3 3 1 3 3 3 0 0 1 2 0 1 3 3 3 1 1 3 0 1 3 3 3 0 1 3 3 3 3\n",
            " 1 3 3 3 3 3 0 1 2 3 1 3 0 3 3 3 2 3 3 3 3 3 3 3 1 3 3 3 3 1 3 3 1 3 1 3 3\n",
            " 1 2 3 3 1 3 3 3 3 3 3 1 3 1 3 3 1 3 3 3 0 0 1 3 1 2 1 3 3 1 3 0 1 1 1 3 3\n",
            " 3 2 3 1 0 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 0 0 0 0 3 2 3\n",
            " 3 1 1 3 0 3 3 3 3 0 3 3 3 3 3 0 1 3 1 1 3 0 0 0 3 3 1 3 3 1 2 3 3 0 1 3 1\n",
            " 3 3 2 3 3 3 1 0 3 2 3 1 2 3 3 0 1 3 3 3 2 3 1 2 1 3 3 3 3 2 3 0 3 1 3 1 3\n",
            " 3 3 3 3 3 2 3 3 3 3 1 1 3 3 3 1 1 2 2 2 3 0 3 2 3 0 0 1 1 2 3 3 3 3 0 1 3\n",
            " 2 3 3 3 3 3 3 3 3 1 3 3 2 0 3 2 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 2 3 3 3\n",
            " 3 3 0 3 3]\n",
            "[3 3 3 3 2 3 0 3 3 3 1 2 2 3 1 3 3 2 3 2 3 3 3 0 3 3 2 2 3 3 3 3 1 3 3 2 3\n",
            " 0 3 3 1 3 2 1 2 2 0 1 3 3 0 0 1 3 3 3 3 0 3 3 1 3 3 0 3 3 3 1 3 3 3 0 3 3\n",
            " 3 3 3 3 3 2 3 1 3 2 2 0 3 1 3 3 3 1 3 3 3 2 3 2 1 1 3 3]\n",
            "Epoch 1/25\n",
            "26/26 [==============================] - 134s 5s/step - loss: 2.8762 - accuracy: 0.5519 - val_loss: 0.9165 - val_accuracy: 0.6484\n",
            "Epoch 2/25\n",
            "26/26 [==============================] - 131s 5s/step - loss: 0.8274 - accuracy: 0.6630 - val_loss: 0.7667 - val_accuracy: 0.6703\n",
            "Epoch 3/25\n",
            "26/26 [==============================] - 137s 5s/step - loss: 0.7470 - accuracy: 0.6862 - val_loss: 0.6324 - val_accuracy: 0.7912\n",
            "Epoch 4/25\n",
            "26/26 [==============================] - 134s 5s/step - loss: 0.6532 - accuracy: 0.7265 - val_loss: 0.5812 - val_accuracy: 0.7582\n",
            "Epoch 5/25\n",
            "26/26 [==============================] - 133s 5s/step - loss: 0.6389 - accuracy: 0.7338 - val_loss: 0.5595 - val_accuracy: 0.7692\n",
            "Epoch 6/25\n",
            "26/26 [==============================] - 131s 5s/step - loss: 0.5103 - accuracy: 0.7839 - val_loss: 0.6031 - val_accuracy: 0.7582\n",
            "Epoch 7/25\n",
            "26/26 [==============================] - 144s 6s/step - loss: 0.4698 - accuracy: 0.8107 - val_loss: 0.3355 - val_accuracy: 0.8462\n",
            "Epoch 8/25\n",
            "26/26 [==============================] - 133s 5s/step - loss: 0.4379 - accuracy: 0.8242 - val_loss: 0.4574 - val_accuracy: 0.8242\n",
            "Epoch 9/25\n",
            "26/26 [==============================] - 135s 5s/step - loss: 0.3241 - accuracy: 0.8730 - val_loss: 0.3119 - val_accuracy: 0.8901\n",
            "Epoch 10/25\n",
            "26/26 [==============================] - 134s 5s/step - loss: 0.2883 - accuracy: 0.8852 - val_loss: 0.2227 - val_accuracy: 0.8901\n",
            "Epoch 11/25\n",
            "26/26 [==============================] - 133s 5s/step - loss: 0.2264 - accuracy: 0.9182 - val_loss: 0.1871 - val_accuracy: 0.9341\n",
            "Epoch 12/25\n",
            "26/26 [==============================] - 143s 6s/step - loss: 0.2181 - accuracy: 0.9072 - val_loss: 0.1704 - val_accuracy: 0.9341\n",
            "Epoch 13/25\n",
            "26/26 [==============================] - 130s 5s/step - loss: 0.2095 - accuracy: 0.9231 - val_loss: 0.0979 - val_accuracy: 0.9670\n",
            "Epoch 14/25\n",
            "26/26 [==============================] - 133s 5s/step - loss: 0.1667 - accuracy: 0.9389 - val_loss: 0.1438 - val_accuracy: 0.9341\n",
            "Epoch 15/25\n",
            "26/26 [==============================] - 133s 5s/step - loss: 0.1901 - accuracy: 0.9292 - val_loss: 0.1696 - val_accuracy: 0.9670\n",
            "Epoch 16/25\n",
            "26/26 [==============================] - 146s 6s/step - loss: 0.1241 - accuracy: 0.9609 - val_loss: 0.2991 - val_accuracy: 0.9121\n",
            "Epoch 17/25\n",
            "26/26 [==============================] - 137s 5s/step - loss: 0.1580 - accuracy: 0.9426 - val_loss: 0.0958 - val_accuracy: 0.9560\n",
            "Epoch 18/25\n",
            "26/26 [==============================] - 131s 5s/step - loss: 0.1419 - accuracy: 0.9475 - val_loss: 0.1512 - val_accuracy: 0.9451\n",
            "Epoch 19/25\n",
            "26/26 [==============================] - 133s 5s/step - loss: 0.1804 - accuracy: 0.9353 - val_loss: 0.1772 - val_accuracy: 0.9670\n",
            "Epoch 20/25\n",
            "26/26 [==============================] - 134s 5s/step - loss: 0.1231 - accuracy: 0.9524 - val_loss: 0.0924 - val_accuracy: 0.9560\n",
            "Epoch 21/25\n",
            "26/26 [==============================] - 140s 5s/step - loss: 0.0703 - accuracy: 0.9695 - val_loss: 0.2121 - val_accuracy: 0.9341\n",
            "Epoch 22/25\n",
            "26/26 [==============================] - 130s 5s/step - loss: 0.0722 - accuracy: 0.9695 - val_loss: 0.0659 - val_accuracy: 0.9670\n",
            "Epoch 23/25\n",
            "26/26 [==============================] - 134s 5s/step - loss: 0.1058 - accuracy: 0.9609 - val_loss: 0.1583 - val_accuracy: 0.9451\n",
            "Epoch 24/25\n",
            "26/26 [==============================] - 134s 5s/step - loss: 0.1211 - accuracy: 0.9573 - val_loss: 0.2241 - val_accuracy: 0.9121\n",
            "Epoch 25/25\n",
            "26/26 [==============================] - 133s 5s/step - loss: 0.0810 - accuracy: 0.9707 - val_loss: 0.0763 - val_accuracy: 0.9780\n"
          ]
        }
      ],
      "source": [
        "\n",
        "input_shape = (256, 256, 3)\n",
        "\n",
        "x_train = np.stack(x_train, axis=0)\n",
        "y_train = np.array(y_train)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1)\n",
        "x_test = np.stack(x_test, axis=0)\n",
        "y_test = np.array(y_test)\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "model = Sequential([\n",
        "    # Convolutional layer with 32 filters, a kernel size of 3x3, and ReLU activation\n",
        "    Conv2D(32, (3, 3), input_shape=input_shape, activation='relu'),\n",
        "    # Max pooling layer with a pool size of 2x2\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Another convolutional layer, increasing the depth\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    # Max pooling layer\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Flatten the 3D output to 1D\n",
        "    Flatten(),\n",
        "    # Dense layer with 256 units\n",
        "    Dense(256, activation='relu'),\n",
        "    # Output layer with N units (one for each class) and softmax activation\n",
        "    Dense(len(labels), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=25)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvlsTH3iqk4O"
      },
      "source": [
        "See model predictions on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwPeD02UYqd4",
        "outputId": "5eb9bf74-dff5-4058-e1f6-1406d9ad3990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 4s 877ms/step\n",
            "[3 3 3 3 2 3 0 3 3 3 1 2 2 3 1 3 3 2 3 2 3 3 3 0 3 3 3 2 3 3 3 3 1 3 3 2 3\n",
            " 3 3 3 3 3 2 1 2 2 0 3 3 3 0 1 1 3 3 3 3 0 3 3 1 3 3 0 3 3 3 1 3 3 3 0 3 3\n",
            " 3 3 3 3 3 2 3 1 1 2 3 0 3 3 3 3 3 1 3 3 3 2 3 3 1 1 3 3]\n",
            "Classification accuracy:  0.9117647058823529\n",
            "[3 3 3 3 2 3 0 3 3 3 1 2 2 3 1 3 3 2 3 2 3 3 3 0 3 3 2 2 3 3 3 3 1 3 3 2 3\n",
            " 0 3 3 1 3 2 1 2 2 0 1 3 3 0 0 1 3 3 3 3 0 3 3 1 3 3 0 3 3 3 1 3 3 3 0 3 3\n",
            " 3 3 3 3 3 2 3 1 3 2 2 0 3 1 3 3 3 1 3 3 3 2 3 2 1 1 3 3]\n",
            "0.39215686274509803\n",
            "[False False False False  True False  True False False False  True  True\n",
            "  True False  True False False  True False  True False False False  True\n",
            " False False False  True False False False False  True False False  True\n",
            " False False False False False False  True  True  True  True  True False\n",
            " False False  True  True  True False False False False  True False False\n",
            "  True False False  True False False False  True False False False  True\n",
            " False False False False False False False  True False  True  True  True\n",
            " False  True False False False False False  True False False False  True\n",
            " False False  True  True False False]\n",
            "[False False False False  True False  True False False False  True  True\n",
            "  True False  True False False  True False  True False False False  True\n",
            " False False  True  True False False False False  True False False  True\n",
            " False  True False False  True False  True  True  True  True  True  True\n",
            " False False  True  True  True False False False False  True False False\n",
            "  True False False  True False False False  True False False False  True\n",
            " False False False False False False False  True False  True False  True\n",
            "  True  True False  True False False False  True False False False  True\n",
            " False  True  True  True False False]\n",
            "26\n",
            "TATP_10k_EXP_SP00003_00066/original/p.jpg\n",
            "37\n",
            "TNT_100ng_EXP_SP00003_00052/original/p3.jpg\n",
            "40\n",
            "RDX_BULK_EXP_SP00000010_00062/original/p1.jpg\n",
            "47\n",
            "RDX_200ng_EXP_SP00000010_00056/original/p.jpg\n",
            "82\n",
            "RDX_1kng_EXP_SP00000010_00057/original/n8.jpg\n",
            "84\n",
            "TATP_3k_Dirty_EXP_SP7814300005_00204/original/p0.jpg\n",
            "87\n",
            "RDX_EXP_SP7814300005_00188/original/p0.jpg\n",
            "97\n",
            "TATP_10k_EXP_SP00003_00067/original/p.jpg\n",
            "P/N accuracy:  0.9215686274509803\n",
            "P/N F1:  0.8918918918918919\n",
            "On  102  samples.\n"
          ]
        }
      ],
      "source": [
        "val_predictions = model.predict(x_test)\n",
        "print(np.argmax(val_predictions, axis=1))\n",
        "preds = np.argmax(val_predictions, axis=1)\n",
        "print(\"Classification accuracy: \", accuracy_score(preds, y_test))\n",
        "print(y_test)\n",
        "\n",
        "p_n_preds = preds != 3\n",
        "p_n_test = y_test != 3\n",
        "\n",
        "print(sum(p_n_test)/len(p_n_test))\n",
        "\n",
        "print(p_n_preds)\n",
        "print(p_n_test)\n",
        "\n",
        "for i in range(len(p_n_test)):\n",
        "  if p_n_test[i] != p_n_preds[i]:\n",
        "    print(i)\n",
        "    print(test_imgs[i])\n",
        "\n",
        "print(\"P/N accuracy: \", accuracy_score(p_n_preds, p_n_test))\n",
        "print(\"P/N F1: \", f1_score(p_n_preds, p_n_test))\n",
        "\n",
        "\n",
        "print(\"On \", len(p_n_test), \" samples.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}